{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>9 hours 47 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kolkata</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>26 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aditya_Jain_lwamvf</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>76.7 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         9 hours 47 mins\n",
       "H2O_cluster_timezone:       Asia/Kolkata\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.1\n",
       "H2O_cluster_version_age:    26 days\n",
       "H2O_cluster_name:           H2O_from_python_Aditya_Jain_lwamvf\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    76.7 Mb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "712/186/102\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Train Data: 1019 |  140\n",
      "Valid Data: 1367 |  1481\n",
      "Test Data: 1257 |  1423\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "\n",
    "# # create dataset - age, bloodtype, healthy eating, lifestyle  & import dataset as \"people\"\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#seed for random number gen\n",
    "np.random.seed(1337)\n",
    "\n",
    "#number of rows, N\n",
    "N = 1000\n",
    "\n",
    "#bloodtypes\n",
    "bloodTypes = np.array(['A', 'A', 'A', 'B', 'AB', 'O', 'O', 'O'])\n",
    "\n",
    "#create the dataframe\n",
    "d = pd.DataFrame({'id':range(N)})\n",
    "\n",
    "#assign bloodtypes\n",
    "d = d.assign(bloodType = bloodTypes[d.id.values %len(bloodTypes)])\n",
    "\n",
    "#assign age between 18 and 85\n",
    "d = d.assign(age = np.random.uniform(18,85,N).round())\n",
    "\n",
    "#randomly assign healthy eating on a scale of 0-9, with a mean of 4 and STD of 2\n",
    "v = np.random.normal(4,2,N).round()\n",
    "v = np.where(v>9,9,v)\n",
    "v = np.where(v<0,0,v)\n",
    "d = d.assign(healthyEating=v)\n",
    "\n",
    "#radomly assign active lifestyle on a scale of 0-9, with a mean of 6 and std of 2\n",
    "v = np.random.normal(6,2,N).round()\n",
    "v = np.where(v>9,9,v)\n",
    "v = np.where(v<0,0,v)\n",
    "d = d.assign(activeLifestyle=v)\n",
    "#people under 35 get a +1 modifier\n",
    "d = d.assign(activeLifestyle = np.where(d.age < 35, d.activeLifestyle +1,d.activeLifestyle))\n",
    "\n",
    "#salary, with a base of $20,000 and modifiers based on healthy eating and active lifestyle\n",
    "v = 20000 + (d.age.values * 3)**2\n",
    "v += d.healthyEating*500\n",
    "v -= d.activeLifestyle*300\n",
    "v += np.random.uniform(0,5000,N)\n",
    "\n",
    "#add noise by rounding\n",
    "d = d.assign(income = v.round(2))\n",
    "\n",
    "#load into H20 dataframe of people\n",
    "people = h2o.H2OFrame(d,destination_frame='people')\n",
    "\n",
    "\n",
    "# # split the data into test, train, and valid \n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#import the h2o data frame as people (i think this is redundant... but i'm leaving it in)\n",
    "people = h2o.get_frame(\"people\")\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#run to verify dataset \"people\" if you want\n",
    "people\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#split into 3 sections, train = 0.7, valid = 0.2, test = (1 - 0.7- 0.1 = )0.1\n",
    "train, valid, test = people.split_frame(\n",
    "    ratios = [0.7,  0.2],\n",
    "    #optional if you aren't viewing in flow... but still good practice to name things\n",
    "    destination_frames = [\"people_train\", \"people_valid\", \"people_test\"],\n",
    "    #optional, but adds more randomization \n",
    "    seed = 1338\n",
    ")\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#test the split if you want\n",
    "print(\"%d/%d/%d\" % (train.nrows, valid.nrows, test.nrows))\n",
    "\n",
    "\n",
    "# # choose gbm and make a model\n",
    "# \n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#import the h20 gbm\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "#set the field we want to find out as y\n",
    "y = \"income\"\n",
    "#ignore the id field and the field we want to find out\n",
    "ignoreFields = [y, \"id\"]\n",
    "x = [i for i in train.names if i not in ignoreFields]\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "#name gbm model \"defaults\" and train on the data, \"x\", solving for y, using train data, \n",
    "# then validating on valid data\n",
    "m1 = H2OGradientBoostingEstimator(model_id = \"defaults\")\n",
    "m1.train(x, y, train, validation_frame = valid)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "#show mae on training data\n",
    "m1.mae(train=True)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "#show mae on validation data\n",
    "m1.mae(valid=True)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "#show mae on test data\n",
    "perf = m1.model_performance(test)\n",
    "perf.mae()\n",
    "\n",
    "\n",
    "# # try some alternative params and build new model\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "#fitting ntrees to 500, (100x what we did before)\n",
    "#fitting max_depth to 20, (4x what we did before)\n",
    "m2 = H2OGradientBoostingEstimator(model_id = \"overfit\", ntrees=5000, max_depth = 20)\n",
    "m2.train(x, y, train, validation_frame = valid)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "#print findins of model 1 (m1) to model 2 (m2)\n",
    "print(\"Train Data: %d |  %d\" % (m1.mae(train=True), m2.mae(train=True)))\n",
    "print(\"Valid Data: %d |  %d\" % (m1.mae(valid=True), m2.mae(valid=True)))\n",
    "print(\"Test Data: %d |  %d\" % (perf.mae(), m2.model_performance(test).mae()))\n",
    "\n",
    "\n",
    "# # As you can see we overfitted by increasing the ntrees of the GBM by 100x and max_depth of trees by 4x. Looking at the graphs of the \"default\" vs \"overfit\" models in h2o flow will validate these findings.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
